
 
 **Model_Ver_1** : Neuron-Layers: 53 70 60 50 30 40 30 20 6 ; Activation: relu ; Output: softmax ; BatchNormalization: False ; Batch size: 3000 ; Epochs: 31 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: he_normal
LR_list: [0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05]
Dev_loss:  2.20661896221e-05   Dev_acc:  0.63856546233
Val_loss:  2.51552777868e-05   Val_acc:  0.622271324629
Test_loss: 2.46970632053e-05   Test_acc: 0.627300087623
Training_time: 148.43

 
 **Model_Ver_2** : Neuron-Layers: 53 70 60 50 30 40 30 20 6 ; Activation: relu ; Output: softmax ; BatchNormalization: False ; Batch size: 3000 ; Epochs: 30 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: he_normal
LR_list: [0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 0.0009999999310821295, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05, 9.99999901978299e-05]
Dev_loss:  7.48816641956e-06   Dev_acc:  0.6489459139
Val_loss:  7.77269793544e-06   Val_acc:  0.643402288335
Test_loss: 7.73192044173e-06   Test_acc: 0.644905267441
Training_time: 460.45

 
 **Model_Ver_3** : Neuron-Layers: 53 70 60 50 30 40 30 20 6 ; Activation: relu ; Output: softmax ; BatchNormalization: False ; Batch size: 3000 ; Epochs: 120 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: he_normal
LR_list: [0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582]
Dev_loss:  7.40034456708e-06   Dev_acc:  0.645331496229
Val_loss:  7.92719163614e-06   Val_acc:  0.637306818037
Test_loss: 7.84359227719e-06   Test_acc: 0.641133743085
Training_time: 1861.85

 
 **Model_Ver_4** : Neuron-Layers: 53 70 60 50 30 40 30 20 6 ; Activation: relu ; Output: softmax ; BatchNormalization: False ; Batch size: 3000 ; Epochs: 120 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: he_normal
Dev_loss:  7.46519997024e-06   Dev_acc:  0.651220600117
Val_loss:  7.7712291453e-06   Val_acc:  0.646564313568
Test_loss: 7.72757211187e-06   Test_acc: 0.647660892978
Training_time: 1858.18


 **Model_Ver_7** : Neuron-Layers: 53 80 70 60 50 30 40 30 20 10 6 ; Activation: relu ; Output: softmax ; BatchNormalization: False ; Batch size: 3000 ; Epochs: 40 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: he_normal
Dev_loss:  5.55692012273e-06   Dev_acc:  0.654445624378
Val_loss:  5.75749819978e-06   Val_acc:  0.650996228428
Test_loss: 5.80049857965e-06   Test_acc: 0.65089478747
Training_time: 953.75

 
 **Model_Ver_8** : Neuron-Layers: 53  70 70 70 70 70 70 70 10 6 ; Activation: relu ; Output: softmax ; BatchNormalization: False ; Batch size: 3000 ; Epochs: 33 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: he_normal
Dev_loss:  5.55144012915e-06   Dev_acc:  0.652695566043
Val_loss:  5.76331439038e-06   Val_acc:  0.648062783344
Test_loss: 5.81667089349e-06   Test_acc: 0.649009019306
Training_time: 979.22

 
 **Model_Ver_9** : Neuron-Layers: 53  80 80 80 80 80 80 80 70 10 6 ; Activation: relu ; Output: softmax ; BatchNormalization: False ; Batch size: 3000 ; Epochs: 29 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: he_normal
Dev_loss:  5.45655080804e-06   Dev_acc:  0.655804002991
Val_loss:  5.75716532047e-06   Val_acc:  0.650158101261
Test_loss: 5.81293114085e-06   Test_acc: 0.651656714002
Training_time: 826.54

 
 **Model_Ver_10** : Neuron-Layers: 53 90 80 70 60 50 40 30 20 15 10 6 ; Activation: relu ; Output: softmax ; BatchNormalization: False ; Batch size: 3000 ; Epochs: 29 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: he_normal
Dev_loss:  5.52308955494e-06   Dev_acc:  0.655713523784
Val_loss:  5.77656130982e-06   Val_acc:  0.650300963846
Test_loss: 5.80086162851e-06   Test_acc: 0.651361467472
Training_time: 630.48

 
 **Model_Ver_11** : Neuron-Layers: 53 100 90 80 70 60 50 40 30 20 15 10 6 ; Activation: relu ; Output: softmax ; BatchNormalization: False ; Batch size: 3000 ; Epochs: 41 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: he_normal
Dev_loss:  4.86904283739e-06   Dev_acc:  0.657473057289
Val_loss:  5.11889296495e-06   Val_acc:  0.65190778947
Test_loss: 5.09384443519e-06   Test_acc: 0.651890857681
Training_time: 1197.79

 
 **Model_Ver_12** : Neuron-Layers: 53 100 90 80 70 60 50 40 30 20 15 10 6 ; Activation: relu ; Output: softmax ; BatchNormalization: False ; Batch size: 1000 ; Epochs: 40 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: he_normal
Dev_loss:  4.8961006045e-06   Dev_acc:  0.657916458547
Val_loss:  5.11481517441e-06   Val_acc:  0.651721539777
Test_loss: 5.06799868527e-06   Test_acc: 0.654947045828
Training_time: 1426.31

 
 **Model_Ver_13** : Neuron-Layers: 53 100 90 80 70 60 50 40 30 20 15 10 6 ; Activation: selu ; Output: softmax ; BatchNormalization: False ; Batch size: 3000 ; Epochs: 34 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: lecun_normal
Dev_loss:  6.27285370523e-06   Dev_acc:  0.662279669376
Val_loss:  6.62113352414e-06   Val_acc:  0.653855363985
Test_loss: 6.58208176919e-06   Test_acc: 0.657643242773
Training_time: 1312.04

 
 **Model_Ver_14** : Neuron-Layers: 53 100 90 80 70 60 50 40 30 20 15 10 6 ; Activation: swish ; Output: softmax ; BatchNormalization: False ; Batch size: 3000 ; Epochs: 29 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: lecun_normal
Dev_loss:  6.38165030989e-06   Dev_acc:  0.654239940133
Val_loss:  6.59407716964e-06   Val_acc:  0.649588557994
Test_loss: 6.54750740972e-06   Test_acc: 0.651460727969
Training_time: 773.16
